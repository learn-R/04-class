---
title: "Sesión N°3"
subtitle: "Importar, validar y exportar datos en R"
date: "23 de agosto 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```


## 0. Objetivo del práctico

1) **Importar bases de datos en diversos formatos**
2) **Seleccionar variables** de las bases de datos importadas
3) Limpiar los datos, eliminando las filas con casos perdidos
4) **Exportar bases de datos** procesadas. 


## 1. Recursos de la práctica

Para el correcto trabajo de estos materiales, deben descargar los datos de la *Encuesta de Caracterización Socioeconómica (CASEN)* en su versión 2020. Para ello, deben dirigirse al [siguiente enlace](https://drive.google.com/drive/folders/1Orgb3Qb9LcjTfjYMdIdy7SWd3xDMrTbG?usp=sharing), descargar el archivo en .zip y luego _input/data_ de su repositorio. Para descomprimir los [archivos revisen](resource/unzipping/). Cuando lo hayan logrado verán la base en formato SPPS `Casen en Pandemia 2020 SPSS.sav` o en STATA `Casen en Pandemia 2020 SPSS.dta`

Recuerden siempre consultar el [**manual/libro de códigos**](http://observatorio.ministeriodesarrollosocial.gob.cl/storage/docs/casen/2020/Libro_de_codigos_Base_de_Datos_Casen_en_Pandemia_2020.pdf) antes de trabajar una base de datos.

## 2. Paquetes a utilizar

En este práctico utilizaremos cuatro paquetes

1. `pacman`: este facilita y agiliza la lectura de los paquetes a utilizar en R

2. `sjmisc`: explorar datos

3. `tidyverse`: colección de paquetes, del cuál utilizaremos `dplyr` y `haven`

4. `haven`: cargar y exportar bases de datos en formatos .sav y .dta

5. `readxl` y `writexl`: para cargar y exportar bases de datos en formato .xlsx y .xls

6. `dplyr`: nos permite seleccionar variables de un set de datos


# Pasos del procesamiento

## 1. Cargar librerías

Dado que ya cargamos `pacman` en el práctico anterior, no lo debemos volver a instalar. Ahora bien, si  cargaremos los nuevos paquetes. Les recordamos que cuando luego de un paquete ponemos `::` esto se refiere a que se *"fuerza"* que esa función provenga de *ese paquete*

```{r packages, include=TRUE}
# ¡Comenta sus funciones!
pacman::p_load(sjmisc,
               sjPlot,
               tidyverse,
               haven,
               readxl,
               writexl)
```

## 2. Importar datos


### 2.1. Cargar set de datos

Una vez cargado el paquete `haven`, procedemos a *importar* los datos anteriormente mencionados. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con `read_sav()`, crearemos un objeto llamado `datos`. Si este procedimiento se logra, esto aparecerá en el *Enviroment*.

**¡Antes!**
Para **importar** los datos en R debemos tener en consideración tres cosas:

1. Cómo se llaman los datos (en nuestro caso Casen en Pandemia 2020 SPSS)

2. El formato de nuestros datos (en nuestro caso .sav)

3. El lugar de donde están alojados nuestros datos. 

¡Ahora sí!
```{r read}
datos <- read_sav("Casen en Pandemia 2020 SPSS.sav")  # No funciona
datos <- read_sav("input/data/casen en pandemia 2020 SPSS.sav") # No funciona
datos <- read_sav("input/data/Casen en Pandemia 2020 SPSS.sav") # ¡Tampoco!
datos <- read_sav("../input/data/Casen en Pandemia 2020 SPSS.sav") 

```

Los dos primeros comandos no funcionan porque

1. La ruta no está bien definida

2. El nombre de la base no es exacto

¡Dos errores muy frecuentes cuando uno se inicia! 

¡Ahora es tu turno! Intenta hacer este procedimiento con los datos en `.dta`. También puedes encontrar este archivo en el enlace.

```{r cargadardatos-intento}

```

### 2.1.1 Cargar set de datos en otros formatos. 

#### a) `.dta`

Este es el formato específico de base de datos para STATA. Por ello, utilizaremos la función `read_dta()` (también está como `read_stata()`), incluida en el paquete `haven`.

```{r,echo = T, include=FALSE, eval = F}
datos <- read_dta("../input/data/Casen en Pandemia 2020 STATA.dta") 
```

#### b) .RData y .rds

*Leer un objeto proveniente de un archivo*

readRDS(file = "datos.rds")

*Leer múltiples objetos a un archivo*
load(file = "datos.RData")

```{r}
load(file = "../input/data/CASEN.RData")
readRDS(file = "../input/data/CASEN.rds")
```

```{r}
datos <- readRDS(file = "../input/data/CASEN.rds")
```


¿Solo contiene datos? ¡No! Además de que puede contener múltiples datos, puede guardar otros *objetos* que se creen en su proceso estadístico. Por ejemplo, *modelos* ¡Lo veremos más adelante!

#### c) `.csv`

Su estructura es muy simple `read.*(file = "datos.*")`. Ahora bien tiene una serie de argumentos que permiten leer de mejor manera los archivos **y de seguro los ocuparás**:

- [`sep`]: indica con qué están separadas las columnas (*; , -*)

- [`dec`]: indica como están separados los decimales (*. ,*)
- [`na-strings`]: indica como están codificados los `NA` (¡podría ser más de una forma!)

- [`encoding`]:puede ser `UTF-8` o `Latin-1`

- [`skip`]: indica el *número* de filas que hay que saltarse (no siempre los csv y excel parten en la primera fila). El argumento `nrow` indica el número de filas máximas a leer

- [`stringsAsFactors`]: si se indica verdadero (`TRUE`) los carácteres serán transformados en factores, lo cuál será muy útil en caso de necesitar hacer análisis.

```{r, eval = F}
datos <- read.csv("../input/data/CASEN.csv", sep=",", 
                  encoding = "UTF-8", stringsAsFactors = F)

head(datos)
```

Muchos problemas, ¡vamos solucionado!

```{r, eval = F}
datos <- read.csv("../input/data/CASEN.csv", sep=";", 
                  encoding = "Latin-1", stringsAsFactors = F, na.strings = c("No sabe", NA))

```


#### d) `.xlsx` 

A partir del paquete `readxl` de `tidyverse` podremos obtener datos que provienen de Excel (tanto en formato `.xls` como `.xlsx`). Ocuparemos la función `read_excel()`, la cual tiene similares argumentos a `read.csv()`

`read_excel("datos.xlsx", sheet = "Hoja 1", range = "A1:C40")`
`read_excel("datos.xlsx", sheet = 2, skip = 4, na = "No sabe")`

```{r}
datos <- readxl::read_excel(path = "../input/data/CASEN.xlsx")
```

¡Hemos sido engañados/as! ¿Cómo solucionar?

```{r}
datos <- readxl::read_excel(path = "../input/data/CASEN.xlsx", sheet = "Hoja1", skip = 1)

datos <- readxl::read_excel(path = "../input/data/CASEN.xlsx", sheet = "Hoja1", skip = 1, na = "NA")

```

Para seguir con este ejercicio volvamos a utilizar la base original en `.dta`

```{r}
datos <- read_dta("../input/data/Casen en Pandemia 2020 SPSS.dta") 
```


## 3. Explorar datos 

Lo más probable es que, una vez importados los datos a utilizar, no trabajemos con el total de variables incluidas en estos (que, en este caso, suman un total de *650* columnas). Es por ello, que debemos **seleccionar** las variables de interés para resolver nuestro problema de investigación (sea el que sea). 

Antes de seleccionar las variables debemos **explorar nuestros datos**, si no ¿cómo saber qué seleccionar y qué no? En R base las funciones clásicas para explorar datos son

```{r}
View(datos) # Ver datos
```

```{r}
names(datos) # Nombre de columnas
dim(datos) # Dimensiones
str(datos) # Estructura de los datos (las clases y categorias de repuesta)
```

A pesar de que son fáciles de aprender, no tienen una visualización muy amena. Un excelente paquete para explorar datos es `sjmisc` quien tiene tres funciones claves:

- [`View_df()`]: que en el visor "Viewer" les mostrará una tabla que tiene el nombre de variable, etiqueta y categorías de respuesta

- [`find_var()`]: que permite indagar en variables que estamos buscando según sus temáticas

- [`frq()`]: nos otorga la distribución univariada de variables categóricas que estamos explorando

- [`descr()`]: nos otorga estadísticos de tendencia central para la variable numérica seleccionada. 

*Ver datos en el visor*
```{r, eval = F }
sjPlot::view_df(datos)
```

*Buscar variables sobre temáticas relacionadas a "vivienda" (no olvides dejarla entre comillas)*
```{r}
find_var(datos, "pobreza")
find_var(datos, "salario")
```

**Explorar distirbución de las variables**
```{r}
frq(datos$pobreza)
```

```{r, echo= F }
frq(datos$y1) #¡Qué feo!
```

Para las variables numeric, en cambio, podemos utilizar la función `descr()` del mismo paquete, que nos indicará las *medidas de tendencia central, dispersión y posición* de la variable.

```{r,echo = T}
descr(datos$y1)
```


#### Sobre las clases de las variables

### a) `numeric`

Una variable puede presentar la clase  `numeric`, lo cual significa que sus datos *sólo incorporan números*. Así, es posible, por ejemplo, calcular el promedio para este tipo de variables. En *Casen en Pandemia 2020*, una de las variables `numeric` incluidas es *Ingreso total per cápita del hogar corregido* (codificada como ypchtotcor).

```{r,echo = T}
class(datos$ypchtotcor)
```

### b) `character`

Una variable de clase `character` puede incluir tanto números como letras. Si bien con estas variables no es posible calcular, por ejemplo, promedios, sí podemos calcular frecuencias (absolutas y relativas), entre otros. 

```{r}
# ¿Un ejemplo?
```

### c) `Logic`

Una variable de clase `Logic` incluye valores lógicos, como TRUE (T) o FALSE (F). Los valores nulos (NA) también son valores lógicos. Este tipo de variables nos pueden servir a la hora de crear funciones, lo cual no se revisará en este práctico.

```{r}
# Otro ejemplo
```

### d) `factor`

Una variable de clase `factor` puede incluir tanto números como letras. Es una especie de variable `character`, pero recodificada de modo que los posibles valores sean etiquetados. Las bases de datos no suelen incluirlas a priori, por lo que lo usual es que debamos realizar un proceso de *recodificación* para poder trabajar una variable como factor. ¡Esto último será tratado en el siguiente práctico!

```{r}
#Un último
```


#### En resumen:

| Clase  | Tipo de variable |
|---------:|:--------|
| `numeric` | Cuantitativa |
| `character` | Categórica |
| `Logic` |  Lógica (TRUE, FALSE, NA) |
| `factor` | Categórica con niveles y etiquetas |


## 3.1. Selección de variables

Nos quedaremos con
- `ypchtotcor`: Ingresos del hogar
- `v13`: "Su hogar, ¿bajo qué situación ocupa la vivienda?"
- `v29`: "¿Cuántos dormitorios de uso exclusivo ocupa su hogar en esta vivienda?"
- `p6`: "¿Cuántas personas viven habitualmente en esta vivienda?"

Crearemos una base procesada llamado `datos_proc`, que sólo incluirá estas tres variables. 

```{r,echo = T, include=FALSE}
datos_proc <- select(datos, ypchtotcor,v13,v29,p6)
```

Como podemos ver en el ambiente (Environment), se creó un nuevo objeto llamado `datos_proc`, que tiene la misma cantidad de observaciones (filas) que datos, pero que sólo incluye 4 de las 650 variables iniciales. 

## 4. Limpieza de datos

Hay diversas maneras de trabajar los valores nulos, tales como realizar procesos de imputación, entre otros. Sin embargo, la más sencilla consiste en **eliminar los valores nulos** que se encuentran presentes en nuestros datos (aunque no recomendable)

Para ello, lo primero es _identificar valores nulos_ en el set de datos en general, o en alguna variable en específico. Para ello, empleamos la función `is.na()`.

```{r, eval=FALSE}

is.na(datos_proc) #Revisamos si hay casos perdidos en el total del set de datos 
is.na(datos_proc$ypchtotcor) #Revisamos si hay casos perdidos en Ingresos per cápita

```

Sin embargo, esto no resulta muy práctico para el análisis. Es por ello que emplearemos la función `sum()` para _contar cuántos valores nulos_ hay en el set de datos en general, o en alguna variable en particular. 

```{r}

sum(is.na(datos_proc)) #Contamos los valores nulos del set de datos en general, que suman un total de 180.148
sum(is.na(datos_proc$ypchtotcor)) #Contaremos los valores nulos de la variable Ingresos per cápita, que alcanzan un total de 98

```

Una vez identificamos los _valores nulos_, podemos proceder a **eliminarlos** del set de datos. El comando `na.omit()` eliminará _todas las filas_ que presenten casos perdidos. 

```{r}
nrow(datos_proc)
datos_proc <- na.omit(datos_proc) #Eliminamos las filas con casos perdidos
nrow(datos_proc) #La nueva base de datos tiene 5.387 filas y 4 columnas
```

¡La próxima sesión aprenderemos a recodificarlas!

## 5. Guardar y exportar datos

Por último, una vez que hayamos procesado los datos, es importante que los **guardemos** en una nueva base de datos procesada, para no tener que llevar a cabo el procesamiento otra vez.

Al igual que en el paso de carga de datos, y a partir del flujo de `input-R-output`propuesto, es esperable que estos datos procesados (o intermedios) los guardemos en `output/data` para que se entienda que provienen de un proceso de manipulación personal

El archivo se puede guardar en distintos formatos: 

### a) .RData y .rds


{{< div "note" >}}
*Guardar un objeto a un archivo*

saveRDS(objecto, file = "datos.rds")

*Guardar un objeto a un archivo*
save(objeto1, objeto2, file = "datos.RData)
{{</div>}}

Es lo recomendable, si el resto del análisis lo realizaremos en R. 

```{r,echo = T}
save(datos_proc, file = "../output/data/datos_proc.RData") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.RData. 

saveRDS(datos_proc, file= "../output/data/datos_proc.rds") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.rds. 
```

### b) .sav (`haven`)

```{r,echo = T}
write_sav(datos_proc, "../output/data/datos_proc.sav") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.sav. 
```

### b) .dta (`haven`)

```{r,echo = T}
write_dta(datos_proc, "../output/data/datos_proc.dta") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.dta. 
```

### b) .csv

```{r,echo = T}
write.csv(datos_proc, "../output/data/datos_proc.csv") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.csv. 
```

### b) .xlsx

```{r,echo = T}
writexl::write_xlsx(datos_proc, "../output/data/datos_proc.xlsx") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.xlsx. 
```

## Resumen

¡Eso es todo por este práctico! Aquí, aprendimos a: 
- 1) Importar datos en diferentes formatos.
- 2) Seleccionar variables (y hacer una revisión de ciertos aspectos de estas).
- 3) Limpiar los datos, eliminando casos perdidos
- 4) Guardar y exportar los datos procesados, en distintos formatos.

## Reporte de progreso

¡Recuerda rellenar tu [reporte de progreso](https://learn-r.formr.org/). Te llegó un código único a tu correo electrónico. Mediante él debes acceder para actualizar tu estado de avance del curso.